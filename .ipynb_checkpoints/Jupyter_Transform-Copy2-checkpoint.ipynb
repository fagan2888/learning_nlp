{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "\n",
    "path = 'data/all_tickers.csv'\n",
    "tickers = pd.read_csv(path,header=None)\n",
    "\n",
    "path = 'data/twt_sample2.csv'\n",
    "df = pd.read_csv(path,header=None,names=['created_at','text', 'label'])\n",
    "df['label'] = df.label.map({'positive':1,'negative':0})\n",
    "df = df.drop(['created_at'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processText(text):\n",
    "    nltk_stops = stopwords.words('english')\n",
    "    avoid_words = set(['URL','user'] + \n",
    "                  list(string.punctuation)).union(nltk_stops)\n",
    "    lemma = WordNetLemmatizer()\n",
    "    x = re.sub(\"\\d+|[^a-zA-Z0-9]\",\" \",text)\n",
    "    return ' '.join([lemma.lemmatize(word.lower()) \n",
    "                     for word in x.split() \n",
    "                         if word not in set(tickers[0].tolist())\n",
    "                         if word not in set(avoid_words)\n",
    "                    ])\n",
    "\n",
    "df['text'] = df['text'].apply(processText)\n",
    "df = df.drop_duplicates('text')\n",
    "df = df[df['text'].str.split().str.len() > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the X data(text) and y data(label)\n",
    "X, y = df['text'], df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline building a text classifier, way easier!\n",
    "# tfid --- ,sublinear_tf=True\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=3, max_features=None,\n",
    "                             strip_accents='unicode', analyzer='word', \n",
    "                             token_pattern=r'\\w{1,}', ngram_range=(1, 3), \n",
    "                             use_idf=1, smooth_idf=1, sublinear_tf=1,\n",
    "                             stop_words='english')),\n",
    "    ('clf', MultinomialNB()) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# grid search classifier building, no parameters yet!\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "parameters={}\n",
    "gsClassifier = GridSearchCV(pipeline, parameters, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=1,\n",
       "     ...f=1,\n",
       "        vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=2, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the training data to the vectorizer and model!\n",
    "gsClassifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine prediction results for X_test\n",
    "y_pred_class = gsClassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7314814814814815\n",
      "Conf Matrx: [[20 16]\n",
      " [13 59]]\n",
      "Clsf Reprt:              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.61      0.56      0.58        36\n",
      "        1.0       0.79      0.82      0.80        72\n",
      "\n",
      "avg / total       0.73      0.73      0.73       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "\n",
    "print ('Accuracy:', metrics.accuracy_score(y_test, y_pred_class))\n",
    "print ('Conf Matrx:', metrics.confusion_matrix(y_test, y_pred_class))\n",
    "print ('Clsf Reprt:', metrics.classification_report(y_test, y_pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
