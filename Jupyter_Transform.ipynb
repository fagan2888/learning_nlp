{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "\n",
    "path = 'data/all_tickers.csv'\n",
    "tickers = pd.read_csv(path,header=None)\n",
    "\n",
    "path = 'data/twt_sample.csv'\n",
    "df = pd.read_csv(path,header=None,names=['created_at','text', 'label'])\n",
    "df['label'] = df.label.map({'positive':1,'negative':0})\n",
    "df = df.drop(['created_at'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processText(text):\n",
    "    nltk_stops = stopwords.words('english')\n",
    "    avoid_words = set(['URL','user'] + \n",
    "                  list(string.punctuation)).union(nltk_stops)\n",
    "    lemma = WordNetLemmatizer()\n",
    "    x = re.sub(\"\\d+|[^a-zA-Z0-9]\",\" \",text)\n",
    "    return ' '.join([lemma.lemmatize(word.lower()) \n",
    "                     for word in x.split() \n",
    "                         if word not in set(tickers[0].tolist())\n",
    "                         if word not in set(avoid_words)\n",
    "                    ])\n",
    "\n",
    "df['text'] = df['text'].apply(processText)\n",
    "df = df.drop_duplicates('text')\n",
    "df = df[df['text'].str.split().str.len() > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the X data(text) and y data(label)\n",
    "X, y = df['text'], df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline building a text classifier, way easier!\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB(fit_prior=False)) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# grid search classifier building, no parameters yet!\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "parameters={'vect__ngram_range': [(1, 1), (1, 3)],\n",
    "            'tfidf__use_idf': (True, False),\n",
    "            'clf__alpha': (1e-2, 1e-3)}\n",
    "gsClassifier = GridSearchCV(pipeline, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        ...near_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'vect__ngram_range': [(1, 1), (1, 3)], 'tfidf__use_idf': (True, False), 'clf__alpha': (0.01, 0.001)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the training data to the vectorizer and model!\n",
    "gsClassifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7387158296249206\n",
      "{'clf__alpha': 0.001, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 3)}\n"
     ]
    }
   ],
   "source": [
    "# machine prediction results for X_test\n",
    "y_pred_class = gsClassifier.predict(X_test)\n",
    "print(gsClassifier.best_score_)\n",
    "print(gsClassifier.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7331639135959339\n",
      "Conf Matrx: [[135 103]\n",
      " [107 442]]\n",
      "Clsf Reprt:              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.56      0.57      0.56       238\n",
      "        1.0       0.81      0.81      0.81       549\n",
      "\n",
      "avg / total       0.73      0.73      0.73       787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "\n",
    "print ('Accuracy:', metrics.accuracy_score(y_test, y_pred_class))\n",
    "print ('Conf Matrx:', metrics.confusion_matrix(y_test, y_pred_class))\n",
    "print ('Clsf Reprt:', metrics.classification_report(y_test, y_pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
